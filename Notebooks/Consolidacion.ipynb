{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do4t0MwnAPYf"
      },
      "source": [
        "<img align=\"right\" width=\"250\" height=\"150\" src=\"https://lh3.googleusercontent.com/p/AF1QipPWZQfa087JiVjutpUTVEGRnh6W214Wjm439gKQ=w1080-h608-p-no-v0\">\n",
        "\n",
        "## **Proyecto:** Retención de usuarios de la Plataforma Digital\n",
        "\n",
        "#### El objetivo de este notebook es incorporar como datos agregados al archivo de Crosseling, los datos de Usuarios, Movimientos, Reclamos y Turnos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-b0ssnalrk6"
      },
      "source": [
        "## Importación de librerias y datos globales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B0Yb19t0Lpvi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # Monto la unidad de drive porque los archivos son muy grandes\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DIR = '/content/drive/MyDrive/Trayecto3-DataDriven/Data/'\n",
        "except:\n",
        "    # Sino lo consigo asumo que estoy trabajando local\n",
        "    DIR = os.path.abspath(r'..\\Data\\Export') + '\\\\'\n",
        "\n",
        "PERIODOS = ['202202', '202203', '202204']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lectura de archivo de usuarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JOTTWO09dQeW",
        "outputId": "a87ae4c5-f04c-42b4-a0c6-542e09dc105f"
      },
      "outputs": [],
      "source": [
        "file = DIR + 'Usuarios.csv'\n",
        "df_usuarios = pd.read_csv(file, encoding='latin-1', parse_dates=[\"FechaCreacion\", \"LAST_LOGIN\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtro los registros que se crearon hace menos de tres meses ya que todos ellos no se pueden evaluar\n",
        "df_usuarios = df_usuarios[df_usuarios['FechaCreacion'] < dt.datetime(2022, 2, 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "fecha_corte =  dt.datetime(2022, 4, 30)\n",
        "df_usuarios[df_usuarios['LAST_LOGIN'] > fecha_corte] = fecha_corte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculo la cantidad de dias desde su último acceso a la plataforma \n",
        "df_usuarios['DIAS_SIN_USAR_PD'] = (fecha_corte - df_usuarios['LAST_LOGIN']).astype('timedelta64[D]').astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Calculo Antiguedad en dias la plataforma\n",
        "df_usuarios['ANTIGUEDAD_PD'] = (df_usuarios['LAST_LOGIN'] - df_usuarios['FechaCreacion']).astype('timedelta64[D]').astype(int)\n",
        "# Filtro los registros sin antiguedad en la plataforma\n",
        "df_usuarios = df_usuarios.loc[df_usuarios['ANTIGUEDAD_PD'] > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Asumo que abandonó la PD si lleva mas de 90 dias sin hacer login\n",
        "df_usuarios[\"ABANDONO_PD\"] = ['Sí' if ( _ > 90 ) else 'No' for _ in df_usuarios[\"DIAS_SIN_USAR_PD\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_USER</th>\n",
              "      <th>FechaCreacion</th>\n",
              "      <th>LAST_LOGIN</th>\n",
              "      <th>SegFactor</th>\n",
              "      <th>FIRST_2_DIGITS_DNI</th>\n",
              "      <th>DIAS_SIN_USAR_PD</th>\n",
              "      <th>ANTIGUEDAD_PD</th>\n",
              "      <th>ABANDONO_PD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6963</th>\n",
              "      <td>787c419b12d7483980fdfeb5a9fa5433</td>\n",
              "      <td>2019-09-20</td>\n",
              "      <td>2019-10-18</td>\n",
              "      <td>SMS</td>\n",
              "      <td>25</td>\n",
              "      <td>925</td>\n",
              "      <td>28</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177224</th>\n",
              "      <td>cc731857fa034b89a5de2d13a49986fc</td>\n",
              "      <td>2020-05-03</td>\n",
              "      <td>2022-02-21</td>\n",
              "      <td>SMS</td>\n",
              "      <td>22</td>\n",
              "      <td>68</td>\n",
              "      <td>659</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31439</th>\n",
              "      <td>3f515fa1e77d4175a7dfad5aa04c8b28</td>\n",
              "      <td>2020-06-19</td>\n",
              "      <td>2020-07-04</td>\n",
              "      <td>SMS</td>\n",
              "      <td>39</td>\n",
              "      <td>665</td>\n",
              "      <td>15</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123015</th>\n",
              "      <td>c6890b1e84f04e74b684eafcc3caf30f</td>\n",
              "      <td>2020-05-13</td>\n",
              "      <td>2021-08-15</td>\n",
              "      <td>SMS</td>\n",
              "      <td>41</td>\n",
              "      <td>258</td>\n",
              "      <td>459</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179824</th>\n",
              "      <td>b697ee6ced99475e8bf677715217db89</td>\n",
              "      <td>2020-09-28</td>\n",
              "      <td>2022-02-28</td>\n",
              "      <td>SMS</td>\n",
              "      <td>25</td>\n",
              "      <td>61</td>\n",
              "      <td>518</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 ID_USER FechaCreacion LAST_LOGIN SegFactor  \\\n",
              "6963    787c419b12d7483980fdfeb5a9fa5433    2019-09-20 2019-10-18       SMS   \n",
              "177224  cc731857fa034b89a5de2d13a49986fc    2020-05-03 2022-02-21       SMS   \n",
              "31439   3f515fa1e77d4175a7dfad5aa04c8b28    2020-06-19 2020-07-04       SMS   \n",
              "123015  c6890b1e84f04e74b684eafcc3caf30f    2020-05-13 2021-08-15       SMS   \n",
              "179824  b697ee6ced99475e8bf677715217db89    2020-09-28 2022-02-28       SMS   \n",
              "\n",
              "       FIRST_2_DIGITS_DNI  DIAS_SIN_USAR_PD  ANTIGUEDAD_PD ABANDONO_PD  \n",
              "6963                   25               925             28          Sí  \n",
              "177224                 22                68            659          No  \n",
              "31439                  39               665             15          Sí  \n",
              "123015                 41               258            459          Sí  \n",
              "179824                 25                61            518          No  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_usuarios.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lectura de archivo de Crosseling\n",
        "\n",
        "Se lee el archivo de crosseling, se filtra para individuos y se cruza con el archivo de usuarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRjSCKgXSiP5",
        "outputId": "b4d65924-b822-4606-a84a-ad9db5a00d7d"
      },
      "outputs": [],
      "source": [
        "def tratar_crosseling(periodo: str, df_usr: pd.DataFrame):\n",
        "\n",
        "  tcols = {\n",
        "    'PERIODO': str,\n",
        "    'ID_USER': str,\n",
        "    'RELACION': str,\n",
        "    'TIPOIMPN': str,\n",
        "    'NATUJURI': str,\n",
        "    'SUCURSAL': str,\n",
        "    'BCRASECT': str,\n",
        "    'BCRASEGO': str,\n",
        "    'GRUPO_CLIENTE': str,\n",
        "    'GRUPOGENERAL': str,\n",
        "    'SUBGRUPO': str,\n",
        "    'SEGMENTO_SUELDOS': str,\n",
        "    'SEGMENTO_BANCAS': str,\n",
        "    'SALDO_COMPUTO_SIST_2': float,\n",
        "    'SALDO_COMPUTO_SIST_CC_MB': float,\n",
        "    'SALDO_COMPUTO_SIST_CA_P': float,\n",
        "    'SALDO_COMPUTO_SIST_CC_P': float,\n",
        "    'SALDO_COMPUTO_SIST_FCI': float,\n",
        "    'FUM': str\n",
        "  }\n",
        "\n",
        "  file = DIR + 'Crosseling_{}.csv'.format(periodo)\n",
        "  df_crosseling = pd.read_csv(file, dtype=tcols, parse_dates=['FUM'], index_col=False)\n",
        "\n",
        "  # Solo me quedo con los 'Individuo sin actividad comercial'\n",
        "  df_crosseling = df_crosseling.loc[df_crosseling['GRUPOGENERAL'] == 'Individuo sin actividad comercial']\n",
        "  df_crosseling.drop('GRUPOGENERAL', axis=1, inplace=True)\n",
        "\n",
        "  # Cruzar con el archivo de usuarios y retornar\n",
        "  return pd.merge(df_usuarios, df_crosseling, how='inner', on = 'ID_USER')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Proceso de incorporación de información de Movimientos\n",
        "\n",
        "El objeto de leer el archivo de movimientos es incorporar a la tabla de crosseling nuevas columnas con información de:\n",
        "\n",
        "- Cantidad de movimientos monetarios y monto total realizados por medio de la plataforma digital\n",
        "- Cantidad de movimientos monetarios y monto total realizados por FUERA de la plataforma digital\n",
        "- Cantidad de movimientos NO monetarios y realizados por medio de la plataforma digital\n",
        "- Cantidad de movimientos NO monetarios y realizados por FUERA de la plataforma digital\n",
        "\n",
        "Total **6** nuevas variables\n",
        "\n",
        "La idea es tener es que el algoritmo de predicción elegido tenga información adicional para poder inferir si el cliente abandona o no la plataforma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tratar_movimientos(periodo: str, df_cons: pd.DataFrame):\n",
        "\n",
        "    uc = [\n",
        "        'ID_USER',\n",
        "        'CANAL_RATIO',\n",
        "        'CANT_OPERACIONES',\n",
        "        'MONTO_TOTAL'\n",
        "    ]\n",
        "\n",
        "    tc = {\n",
        "        'ID_USER': str,\n",
        "        'CANAL_RATIO': str,\n",
        "        'CANT_OPERACIONES': int,\n",
        "        'MONTO_TOTAL': float,\n",
        "    }\n",
        "\n",
        "    df_estudio = df_cons\n",
        "    \n",
        "    #### Transacciones Monetarias ####\n",
        "\n",
        "    file = DIR + r'Sum_Trx_Monetarias_{}.csv'.format(periodo)\n",
        "    df_tx = pd.read_csv(file, index_col=False, dtype=tc, usecols=uc)\n",
        "\n",
        "    # Agrupo y sumarizo los registros por canales digitales y no digitales\n",
        "    df_tx = df_tx.groupby([\n",
        "        'ID_USER',\n",
        "        'CANAL_RATIO']) \\\n",
        "        .aggregate('sum') \\\n",
        "        .sort_values(by='ID_USER') \\\n",
        "        .reset_index()\n",
        "\n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']=='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES', 'MONTO_TOTAL']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_MON_DIG', 'MONTO_TOTAL': 'MONT_OP_MON_DIG'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal NO digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']!='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES', 'MONTO_TOTAL']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_MON_OTR', 'MONTO_TOTAL': 'MONT_OP_MON_OTR'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    #### Transacciones No Monetarias ####\n",
        "    file = DIR + r'Sum_Trx_NoMonetarias_{}.csv'.format(periodo)\n",
        "    df_tx = pd.read_csv(file, index_col=False, dtype=tc, usecols=uc)\n",
        "\n",
        "    # Agrupo los registros por canales digitales y no digitales\n",
        "    df_tx = df_tx.groupby([\n",
        "        'ID_USER',\n",
        "        'CANAL_RATIO']) \\\n",
        "        .aggregate('sum') \\\n",
        "        .sort_values(by='ID_USER') \\\n",
        "        .reset_index()\n",
        "        \n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']=='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_NOMON_DIG'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal NO digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']!='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_NOMON_OTR'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    # Convertir las columnas de cantidades a enteros previo sacar los valores nulos\n",
        "    for i in ['CANT_OP_MON_DIG', 'CANT_OP_MON_OTR', 'CANT_OP_NOMON_DIG', 'CANT_OP_NOMON_OTR']:\n",
        "        df_estudio[i] = df_estudio[i].fillna(0)\n",
        "        df_estudio[i] = df_estudio[i].astype(int)\n",
        "        \n",
        "    # Eliminar los nulos de los montos\n",
        "    for i in ['MONT_OP_MON_DIG', 'MONT_OP_MON_OTR']:\n",
        "        df_estudio[i] = df_estudio[i].fillna(0)\n",
        "\n",
        "    return df_estudio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Proceso de incorporación de información de Reclamos\n",
        "\n",
        "El objeto de leer el archivo de reclamos es incorporar a la tabla de crosseling una nueva columnas con información de:\n",
        "\n",
        "- Cantidad de tickets registrados para la plataforma BANCON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tratar_reclamos(periodo: str, df_cons: pd.DataFrame):\n",
        "\n",
        "    file = DIR + 'Gestar_{}.csv'.format(periodo)\n",
        "\n",
        "    df_gt = pd.read_csv(file, usecols=['ID_USER', 'TYPE MOTIVO GESTION BANCON'], index_col=False)\n",
        "\n",
        "    # Me quedo solo con lo que son Reclamos de BANCON y los cuento por usuario\n",
        "    df_gt = df_gt[df_gt['TYPE MOTIVO GESTION BANCON'].notnull()]\n",
        "    df_gt = df_gt.groupby(by=['ID_USER']).size().to_frame().reset_index()\n",
        "    df_gt.columns = ['ID_USER', 'CANT_REC_PD']\n",
        "\n",
        "    df_estudio = pd.merge(df_cons, df_gt, how='left', on='ID_USER', indicator=False)\n",
        "\n",
        "    # Convertir las columnas de cantidades a enteros previo sacar los valores nulos\n",
        "    df_estudio['CANT_REC_PD'] = df_estudio['CANT_REC_PD'].fillna(0)\n",
        "    df_estudio['CANT_REC_PD'] = df_estudio['CANT_REC_PD'].astype(int)\n",
        "\n",
        "    return df_estudio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Proceso Principal de incorporación de información al dataframe de Crosseling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\e21719832\\Documents\\Python\\trayecto3\\Data\\Export\\Crosseling_ampliado_202202.csv\n",
            "c:\\Users\\e21719832\\Documents\\Python\\trayecto3\\Data\\Export\\Crosseling_ampliado_202203.csv\n",
            "c:\\Users\\e21719832\\Documents\\Python\\trayecto3\\Data\\Export\\Crosseling_ampliado_202204.csv\n"
          ]
        }
      ],
      "source": [
        "for periodo in PERIODOS:\n",
        "    \n",
        "    df_parcial = tratar_crosseling(periodo, df_usuarios)\n",
        "    df_parcial = tratar_movimientos(periodo, df_parcial)\n",
        "    df_parcial = tratar_reclamos(periodo, df_parcial)\n",
        "    \n",
        "    #### Grabar ####\n",
        "    file = DIR + 'Crosseling_ampliado_{}.csv'.format(periodo)\n",
        "    df_parcial.to_csv(file, index=False)\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "do4t0MwnAPYf",
        "N-b0ssnalrk6",
        "1GEQg1Rnou84"
      ],
      "name": "Abandono_Retención_Usuarios_BANCON.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "9a5f32d0676542e4e2bf7db8487c84e3169d994048782af8503f70e03a7f1e48"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
