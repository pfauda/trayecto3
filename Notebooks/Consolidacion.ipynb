{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do4t0MwnAPYf"
      },
      "source": [
        "<img align=\"right\" width=\"250\" height=\"150\" src=\"https://lh3.googleusercontent.com/p/AF1QipPWZQfa087JiVjutpUTVEGRnh6W214Wjm439gKQ=w1080-h608-p-no-v0\">\n",
        "\n",
        "## **Proyecto:** Retención de usuarios de la Plataforma Digital\n",
        "\n",
        "#### El objetivo de este notebook es incorporar como datos agregados al archivo de Crosseling, los datos de Usuarios, Movimientos y Reclamos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-b0ssnalrk6"
      },
      "source": [
        "## Importación de librerias y datos globales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "B0Yb19t0Lpvi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "LOCAL = True\n",
        "if LOCAL:\n",
        "    dir = os.path.abspath(r'..\\Data\\Export') + '\\\\'\n",
        "else:\n",
        "    # Monto la unidad de drive porque los archivos son muy grandes\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    dir = '/content/drive/MyDrive/Trayecto3-DataDriven/Data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lectura de archivo de usuarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JOTTWO09dQeW",
        "outputId": "a87ae4c5-f04c-42b4-a0c6-542e09dc105f"
      },
      "outputs": [],
      "source": [
        "file = dir + 'Usuarios.csv'\n",
        "df_usuarios = pd.read_csv(file, encoding='latin-1', parse_dates=[\"FechaCreacion\", \"LAST_LOGIN\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtro los registros que se crearon hace menos de tres meses ya que todos ellos no se pueden evaluar\n",
        "df_usuarios = df_usuarios[df_usuarios['FechaCreacion'] < dt.datetime(2022, 2, 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [],
      "source": [
        "fecha_corte =  dt.datetime(2022, 4, 30)\n",
        "df_usuarios[df_usuarios['LAST_LOGIN'] > fecha_corte] = fecha_corte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculo la cantidad de dias desde su último acceso a la plataforma \n",
        "df_usuarios['DIAS_SIN_USAR_PD'] = (fecha_corte - df_usuarios['LAST_LOGIN']).astype('timedelta64[D]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Calculo Antiguedad en dias la plataforma\n",
        "df_usuarios['ANTIGUEDAD_PD'] = (df_usuarios['LAST_LOGIN'] - df_usuarios['FechaCreacion']).astype('timedelta64[D]')\n",
        "# Filtro los registros sin antiguedad en la plataforma\n",
        "df_usuarios = df_usuarios.loc[df_usuarios['ANTIGUEDAD_PD'] > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Asumo que abandonó la PD si lleva mas de 90 dias sin hacer login\n",
        "df_usuarios[\"ABANDONO_PD\"] = ['Sí' if ( _ > 90 ) else 'No' for _ in df_usuarios[\"DIAS_SIN_USAR_PD\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_USER</th>\n",
              "      <th>FechaCreacion</th>\n",
              "      <th>LAST_LOGIN</th>\n",
              "      <th>SegFactor</th>\n",
              "      <th>DIAS_SIN_USAR_PD</th>\n",
              "      <th>ANTIGUEDAD_PD</th>\n",
              "      <th>ABANDONO_PD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>93689</th>\n",
              "      <td>43241bd2c0234b18ab24563eecb873cc</td>\n",
              "      <td>2020-12-28</td>\n",
              "      <td>2021-03-29</td>\n",
              "      <td>SMS</td>\n",
              "      <td>397.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204662</th>\n",
              "      <td>978c21070c694fa09388c4c47e16b638</td>\n",
              "      <td>2019-06-03</td>\n",
              "      <td>2022-04-14</td>\n",
              "      <td>SMS</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1046.0</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163275</th>\n",
              "      <td>8ec1c6bf3d934ff3b3d464ae03d8f6c5</td>\n",
              "      <td>2020-07-25</td>\n",
              "      <td>2022-01-12</td>\n",
              "      <td>SMS</td>\n",
              "      <td>108.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88700</th>\n",
              "      <td>541ec181d4614eb1a6d43588e1a8014a</td>\n",
              "      <td>2020-05-27</td>\n",
              "      <td>2021-03-03</td>\n",
              "      <td>SMS</td>\n",
              "      <td>423.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38346</th>\n",
              "      <td>6acf8f1670fc459b9b7b3fdd0adec20b</td>\n",
              "      <td>2020-05-11</td>\n",
              "      <td>2020-08-04</td>\n",
              "      <td>SMS</td>\n",
              "      <td>634.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 ID_USER FechaCreacion LAST_LOGIN SegFactor  \\\n",
              "93689   43241bd2c0234b18ab24563eecb873cc    2020-12-28 2021-03-29       SMS   \n",
              "204662  978c21070c694fa09388c4c47e16b638    2019-06-03 2022-04-14       SMS   \n",
              "163275  8ec1c6bf3d934ff3b3d464ae03d8f6c5    2020-07-25 2022-01-12       SMS   \n",
              "88700   541ec181d4614eb1a6d43588e1a8014a    2020-05-27 2021-03-03       SMS   \n",
              "38346   6acf8f1670fc459b9b7b3fdd0adec20b    2020-05-11 2020-08-04       SMS   \n",
              "\n",
              "        DIAS_SIN_USAR_PD  ANTIGUEDAD_PD ABANDONO_PD  \n",
              "93689              397.0           91.0          Sí  \n",
              "204662              16.0         1046.0          No  \n",
              "163275             108.0          536.0          Sí  \n",
              "88700              423.0          280.0          Sí  \n",
              "38346              634.0           85.0          Sí  "
            ]
          },
          "execution_count": 237,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_usuarios.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lectura de archivo de Crosseling\n",
        "\n",
        "Se lee el archivo de crosseling, se filtra para individuos y se cruza con el archivo de usuarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRjSCKgXSiP5",
        "outputId": "b4d65924-b822-4606-a84a-ad9db5a00d7d"
      },
      "outputs": [],
      "source": [
        "def tratar_crosseling(periodo: str, df_usr: pd.DataFrame):\n",
        "\n",
        "  tcols = {\n",
        "    'PERIODO': str,\n",
        "    'ID_USER': str,\n",
        "    'RELACION': str,\n",
        "    'TIPOIMPN': str,\n",
        "    'NATUJURI': str,\n",
        "    'SUCURSAL': str,\n",
        "    'BCRASECT': str,\n",
        "    'BCRASEGO': str,\n",
        "    'GRUPO_CLIENTE': str,\n",
        "    'GRUPOGENERAL': str,\n",
        "    'SUBGRUPO': str,\n",
        "    'SEGMENTO_SUELDOS': str,\n",
        "    'SEGMENTO_BANCAS': str,\n",
        "    'SALDO_COMPUTO_SIST_2': float,\n",
        "    'SALDO_COMPUTO_SIST_CC_MB': float,\n",
        "    'SALDO_COMPUTO_SIST_CA_P': float,\n",
        "    'SALDO_COMPUTO_SIST_CC_P': float,\n",
        "    'SALDO_COMPUTO_SIST_FCI': float,\n",
        "    'FUM': str\n",
        "  }\n",
        "\n",
        "  file = dir + 'Crosseling_{}.csv'.format(periodo)\n",
        "  df_crosseling = pd.read_csv(file, dtype=tcols, parse_dates=['FUM'], index_col=False)\n",
        "\n",
        "  # Solo me quedo con los 'Individuo sin actividad comercial'\n",
        "  df_crosseling = df_crosseling.loc[df_crosseling['GRUPOGENERAL'] == 'Individuo sin actividad comercial']\n",
        "  df_crosseling.drop('GRUPOGENERAL', axis=1, inplace=True)\n",
        "\n",
        "  # Cruzar con el archivo de usuarios y retornar\n",
        "  return pd.merge(df_usuarios, df_crosseling, how='inner', on = 'ID_USER')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Archivo de movimientos\n",
        "\n",
        "El objeto de leer el archivo de movimientos es incorporar a la tabla de crosseling nuevas columnas con información de:\n",
        "\n",
        "- Cantidad de movimientos monetarios y monto total realizados por medio de la plataforma digital\n",
        "- Cantidad de movimientos monetarios y monto total realizados por FUERA de la plataforma digital\n",
        "- Cantidad de movimientos NO monetarios y realizados por medio de la plataforma digital\n",
        "- Cantidad de movimientos NO monetarios y realizados por FUERA de la plataforma digital\n",
        "\n",
        "Total **6** nuevas variables\n",
        "\n",
        "La idea es tener es que el algoritmo de predicción elegido tenga información adicional para poder inferir si el cliente abandona o no la plataforma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tratar_movimientos(periodo: str, df_cons: pd.DataFrame):\n",
        "\n",
        "    uc = [\n",
        "        'ID_USER',\n",
        "        'CANAL_RATIO',\n",
        "        'CANT_OPERACIONES',\n",
        "        'MONTO_TOTAL'\n",
        "    ]\n",
        "\n",
        "    tc = {\n",
        "        'ID_USER': str,\n",
        "        'CANAL_RATIO': str,\n",
        "        'CANT_OPERACIONES': int,\n",
        "        'MONTO_TOTAL': float,\n",
        "    }\n",
        "\n",
        "    df_estudio = df_cons\n",
        "    \n",
        "    #### Transacciones Monetarias ####\n",
        "\n",
        "    file = dir + r'Sum_Trx_Monetarias_{}.csv'.format(periodo)\n",
        "    df_tx = pd.read_csv(file, index_col=False, dtype=tc, usecols=uc)\n",
        "\n",
        "    # Agrupo y sumarizo los registros por canales digitales y no digitales\n",
        "    df_tx = df_tx.groupby([\n",
        "        'ID_USER',\n",
        "        'CANAL_RATIO']) \\\n",
        "        .aggregate('sum') \\\n",
        "        .sort_values(by='ID_USER') \\\n",
        "        .reset_index()\n",
        "\n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']=='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES', 'MONTO_TOTAL']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_MON_DIG', 'MONTO_TOTAL': 'MONT_OP_MON_DIG'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal NO digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']!='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES', 'MONTO_TOTAL']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_MON_OTR', 'MONTO_TOTAL': 'MONT_OP_MON_OTR'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    #### Transacciones No Monetarias ####\n",
        "    file = dir + r'Sum_Trx_NoMonetarias_{}.csv'.format(periodo)\n",
        "    df_tx = pd.read_csv(file, index_col=False, dtype=tc, usecols=uc)\n",
        "\n",
        "    # Agrupo los registros por canales digitales y no digitales\n",
        "    df_tx = df_tx.groupby([\n",
        "        'ID_USER',\n",
        "        'CANAL_RATIO']) \\\n",
        "        .aggregate('sum') \\\n",
        "        .sort_values(by='ID_USER') \\\n",
        "        .reset_index()\n",
        "        \n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']=='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_NOMON_DIG'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal NO digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']!='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_NOMON_OTR'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    # Convertir las columnas de cantidades a enteros previo sacar los valores nulos\n",
        "    for i in ['CANT_OP_MON_DIG', 'CANT_OP_MON_OTR', 'CANT_OP_NOMON_DIG', 'CANT_OP_NOMON_OTR']:\n",
        "        df_estudio[i] = df_estudio[i].fillna(0)\n",
        "        df_estudio[i] = df_estudio[i].astype(int)\n",
        "        \n",
        "    # Eliminar los nulos de los montos\n",
        "    for i in ['MONT_OP_MON_DIG', 'MONT_OP_MON_OTR']:\n",
        "        df_estudio[i] = df_estudio[i].fillna(0)\n",
        "\n",
        "    return df_estudio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Archivo de reclamos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tratar_reclamos(periodo: str, df_cons: pd.DataFrame):\n",
        "\n",
        "    file = dir + 'Gestar_{}.csv'.format(periodo)\n",
        "\n",
        "    df_gestar = pd.read_csv(file, usecols=['ID_USER', 'STATEID', 'NIVEL 1'], index_col=False)\n",
        "\n",
        "    # Me quedo solo con lo que son Reclamos y Quejas que se encuentren en estado CERRRADO o DERIVADO\n",
        "    df_gestar = df_gestar[(((df_gestar['NIVEL 1']=='Reclamos') | (df_gestar['NIVEL 1']=='Queja')) & ((df_gestar['STATEID']==4) | (df_gestar['STATEID']==6)))]\n",
        "\n",
        "    # Agrupo por estado del reclamo\n",
        "    df_rec_agrup = df_gestar.groupby(['ID_USER', 'STATEID']) \\\n",
        "        .aggregate('count') \\\n",
        "        .sort_values(by='ID_USER') \\\n",
        "        .reset_index()\n",
        "    df_rec_agrup.rename(columns={'NIVEL 1': 'CANT_RECL'}, inplace=True)\n",
        "\n",
        "    # Pongo en columnas la cantidad de reclamos DERIVADOS\n",
        "    df_rec_join = df_rec_agrup \\\n",
        "        .loc[(df_rec_agrup['STATEID']==4), ['ID_USER', 'CANT_RECL']] \\\n",
        "        .rename(columns = {'CANT_RECL': 'CANT_RECL_A'})\n",
        "    df_estudio = pd.merge(df_estudio, df_rec_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    # Pongo en columnas la cantidad de reclamos CERRRADOS\n",
        "    df_rec_join = df_rec_agrup \\\n",
        "        .loc[(df_rec_agrup['STATEID']==6), ['ID_USER', 'CANT_RECL']] \\\n",
        "        .rename(columns = {'CANT_RECL': 'CANT_RECL_C'})\n",
        "    df_estudio = pd.merge(df_estudio, df_rec_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    # Convertir las columnas de cantidades a enteros previo sacar los valores nulos\n",
        "    for i in ['CANT_RECL_A', 'CANT_RECL_A']:\n",
        "        df_estudio[i] = df_estudio[i].fillna(0)\n",
        "        df_estudio[i] = df_estudio[i].astype(int)\n",
        "\n",
        "    return df_estudio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\e21719832\\Documents\\Python\\trayecto3\\Data\\Export\\Crosseling_ampliado_202202.csv\n",
            "c:\\Users\\e21719832\\Documents\\Python\\trayecto3\\Data\\Export\\Crosseling_ampliado_202203.csv\n",
            "c:\\Users\\e21719832\\Documents\\Python\\trayecto3\\Data\\Export\\Crosseling_ampliado_202204.csv\n"
          ]
        }
      ],
      "source": [
        "for periodo in ['202202', '202203', '202204']:\n",
        "    \n",
        "    df_parcial = tratar_crosseling(periodo, df_usuarios)\n",
        "    df_parcial = tratar_movimientos(periodo, df_parcial)\n",
        "    df_parcial = tratar_reclamos(periodo, df_parcial)\n",
        "    \n",
        "    #### Grabar ####\n",
        "    file = dir + 'Crosseling_ampliado_{}.csv'.format(periodo)\n",
        "    df_parcial.to_csv(file, index=False)\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_estudio[((df_estudio['MONT_OP_MON_OTR']!=0) & (df_estudio['MONT_OP_MON_DIG']!=0) & (df_estudio['CANT_OP_NOMON_DIG']!=0) & (df_estudio['CANT_OP_NOMON_OTR']!=0))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file = dir + 'Gestar_{}.csv'.format('202204')\n",
        "\n",
        "df_gestar = pd.read_csv(file, usecols=['ID_USER', 'STATEID', 'NIVEL 1'], index_col=False)\n",
        "\n",
        "# Me quedo solo con lo que son Reclamos y Quejas que se encuentren en estado CERRRADO o DERIVADO\n",
        "df_gestar = df_gestar[(((df_gestar['NIVEL 1']=='Reclamos') | (df_gestar['NIVEL 1']=='Queja')) & ((df_gestar['STATEID']==4) | (df_gestar['STATEID']==6)))]\n",
        "\n",
        "df_rec_agrup = df_gestar.groupby(['ID_USER', 'STATEID']) \\\n",
        "    .aggregate('count') \\\n",
        "    .sort_values(by='ID_USER') \\\n",
        "    .reset_index()\n",
        "    \n",
        "df_rec_agrup.rename(columns={'NIVEL 1': 'CANT_RECL'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_rec_agrup.sort_values(by='CANT_RECL')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "do4t0MwnAPYf",
        "N-b0ssnalrk6",
        "1GEQg1Rnou84"
      ],
      "name": "Abandono_Retención_Usuarios_BANCON.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "9a5f32d0676542e4e2bf7db8487c84e3169d994048782af8503f70e03a7f1e48"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
