{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do4t0MwnAPYf"
      },
      "source": [
        "<img align=\"right\" width=\"250\" height=\"150\" src=\"https://lh3.googleusercontent.com/p/AF1QipPWZQfa087JiVjutpUTVEGRnh6W214Wjm439gKQ=w1080-h608-p-no-v0\">\n",
        "\n",
        "## **Proyecto:** Retención de usuarios de la Plataforma Digital\n",
        "\n",
        "#### El objetivo de este notebook es incorporar como datos agregados al archivo de Crosseling, los datos de Usuarios, Movimientos, Reclamos y Turnos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-b0ssnalrk6"
      },
      "source": [
        "## Importación de librerias y datos globales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B0Yb19t0Lpvi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # Monto la unidad de drive porque los archivos son muy grandes\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DIR = '/content/drive/MyDrive/Trayecto3-DataDriven/Data/'\n",
        "except:\n",
        "    # Sino lo consigo asumo que estoy trabajando local\n",
        "    DIR = os.path.abspath(r'..\\Data\\Export') + '\\\\'\n",
        "\n",
        "PERIODOS = ['202202', '202203', '202204']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lectura de archivo de usuarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JOTTWO09dQeW",
        "outputId": "a87ae4c5-f04c-42b4-a0c6-542e09dc105f"
      },
      "outputs": [],
      "source": [
        "file = DIR + 'Usuarios.parquet'\n",
        "df_usuarios = pd.read_parquet(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtro los registros que se crearon hace menos de tres meses ya que todos ellos no se pueden evaluar\n",
        "df_usuarios = df_usuarios[df_usuarios['FechaCreacion'] < dt.datetime(2022, 2, 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "fecha_corte =  dt.datetime(2022, 4, 30)\n",
        "df_usuarios[df_usuarios['LAST_LOGIN'] > fecha_corte] = fecha_corte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculo la cantidad de dias desde su último acceso a la plataforma \n",
        "df_usuarios['DIAS_SIN_USAR_PD'] = (fecha_corte - df_usuarios['LAST_LOGIN']).astype('timedelta64[D]').astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Calculo Antiguedad en dias la plataforma\n",
        "df_usuarios['ANTIGUEDAD_PD'] = (df_usuarios['LAST_LOGIN'] - df_usuarios['FechaCreacion']).astype('timedelta64[D]').astype(int)\n",
        "# Filtro los registros sin antiguedad en la plataforma\n",
        "df_usuarios = df_usuarios.loc[df_usuarios['ANTIGUEDAD_PD'] > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Asumo que abandonó la PD si lleva mas de 90 dias sin hacer login\n",
        "df_usuarios[\"ABANDONO_PD\"] = ['Sí' if ( _ > 90 ) else 'No' for _ in df_usuarios[\"DIAS_SIN_USAR_PD\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_USER</th>\n",
              "      <th>FechaCreacion</th>\n",
              "      <th>LAST_LOGIN</th>\n",
              "      <th>SegFactor</th>\n",
              "      <th>FIRST_2_DIGITS_DNI</th>\n",
              "      <th>DIAS_SIN_USAR_PD</th>\n",
              "      <th>ANTIGUEDAD_PD</th>\n",
              "      <th>ABANDONO_PD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>121979</th>\n",
              "      <td>ac744f4dcd90403fb87401a439b946ad</td>\n",
              "      <td>2020-07-24</td>\n",
              "      <td>2021-08-10</td>\n",
              "      <td>SMS</td>\n",
              "      <td>04</td>\n",
              "      <td>263</td>\n",
              "      <td>382</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143086</th>\n",
              "      <td>248577211cd045a29e21697b6161eaaa</td>\n",
              "      <td>2021-05-10</td>\n",
              "      <td>2021-11-01</td>\n",
              "      <td>Softoken</td>\n",
              "      <td>42</td>\n",
              "      <td>180</td>\n",
              "      <td>175</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48624</th>\n",
              "      <td>4b721951474c473e81f938825550d131</td>\n",
              "      <td>2020-06-18</td>\n",
              "      <td>2020-09-08</td>\n",
              "      <td>SMS</td>\n",
              "      <td>10</td>\n",
              "      <td>599</td>\n",
              "      <td>82</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150091</th>\n",
              "      <td>211afad6b3b24e71b92571bb6d505397</td>\n",
              "      <td>2021-03-04</td>\n",
              "      <td>2021-11-26</td>\n",
              "      <td>SMS</td>\n",
              "      <td>18</td>\n",
              "      <td>155</td>\n",
              "      <td>267</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127621</th>\n",
              "      <td>a2d0dd13339f41d4981d1fe9aace414b</td>\n",
              "      <td>2020-05-30</td>\n",
              "      <td>2021-09-04</td>\n",
              "      <td>SMS</td>\n",
              "      <td>35</td>\n",
              "      <td>238</td>\n",
              "      <td>462</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 ID_USER FechaCreacion LAST_LOGIN SegFactor  \\\n",
              "121979  ac744f4dcd90403fb87401a439b946ad    2020-07-24 2021-08-10       SMS   \n",
              "143086  248577211cd045a29e21697b6161eaaa    2021-05-10 2021-11-01  Softoken   \n",
              "48624   4b721951474c473e81f938825550d131    2020-06-18 2020-09-08       SMS   \n",
              "150091  211afad6b3b24e71b92571bb6d505397    2021-03-04 2021-11-26       SMS   \n",
              "127621  a2d0dd13339f41d4981d1fe9aace414b    2020-05-30 2021-09-04       SMS   \n",
              "\n",
              "       FIRST_2_DIGITS_DNI  DIAS_SIN_USAR_PD  ANTIGUEDAD_PD ABANDONO_PD  \n",
              "121979                 04               263            382          Sí  \n",
              "143086                 42               180            175          Sí  \n",
              "48624                  10               599             82          Sí  \n",
              "150091                 18               155            267          Sí  \n",
              "127621                 35               238            462          Sí  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_usuarios.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lectura de archivo de Crosseling\n",
        "\n",
        "Se lee el archivo de crosseling, se filtra para individuos y se cruza con el archivo de usuarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRjSCKgXSiP5",
        "outputId": "b4d65924-b822-4606-a84a-ad9db5a00d7d"
      },
      "outputs": [],
      "source": [
        "def tratar_crosseling(periodo: str, df_usr: pd.DataFrame):\n",
        "\n",
        "  file = DIR + 'Crosseling_{}.parquet'.format(periodo)\n",
        "  df_crosseling = pd.read_parquet(file)\n",
        "\n",
        "  # Solo me quedo con los 'Individuo sin actividad comercial'\n",
        "  df_crosseling = df_crosseling.loc[df_crosseling['GRUPOGENERAL'] == 'Individuo sin actividad comercial']\n",
        "  df_crosseling.drop('GRUPOGENERAL', axis=1, inplace=True)\n",
        "\n",
        "  # Cruzar con el archivo de usuarios y retornar\n",
        "  return pd.merge(df_usuarios, df_crosseling, how='inner', on = 'ID_USER')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Proceso de incorporación de información de Movimientos\n",
        "\n",
        "El objeto de leer el archivo de movimientos es incorporar a la tabla de crosseling nuevas columnas con información de:\n",
        "\n",
        "- Cantidad de movimientos monetarios y monto total realizados por medio de la plataforma digital\n",
        "- Cantidad de movimientos monetarios y monto total realizados por FUERA de la plataforma digital\n",
        "- Cantidad de movimientos NO monetarios y realizados por medio de la plataforma digital\n",
        "- Cantidad de movimientos NO monetarios y realizados por FUERA de la plataforma digital\n",
        "\n",
        "Total **6** nuevas variables\n",
        "\n",
        "La idea es tener es que el algoritmo de predicción elegido tenga información adicional para poder inferir si el cliente abandona o no la plataforma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tratar_movimientos(periodo: str, df_cons: pd.DataFrame):\n",
        "\n",
        "    uc = [\n",
        "            'ID_USER',\n",
        "            'CANAL_RATIO',\n",
        "            'CANT_OPERACIONES',\n",
        "            'MONTO_TOTAL'\n",
        "        ]\n",
        "\n",
        "    df_estudio = df_cons\n",
        "    \n",
        "    #### Transacciones Monetarias ####\n",
        "\n",
        "    file = DIR + r'Sum_Trx_Monetarias_{}.parquet'.format(periodo)\n",
        "    df_tx = pd.read_parquet(file, columns=uc)\n",
        "\n",
        "    # Agrupo y sumarizo los registros por canales digitales y no digitales\n",
        "    df_tx = df_tx.groupby([\n",
        "        'ID_USER',\n",
        "        'CANAL_RATIO']) \\\n",
        "        .aggregate('sum') \\\n",
        "        .sort_values(by='ID_USER') \\\n",
        "        .reset_index()\n",
        "\n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']=='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES', 'MONTO_TOTAL']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_MON_DIG', 'MONTO_TOTAL': 'MONT_OP_MON_DIG'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal NO digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']!='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES', 'MONTO_TOTAL']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_MON_OTR', 'MONTO_TOTAL': 'MONT_OP_MON_OTR'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    #### Transacciones No Monetarias ####\n",
        "    file = DIR + r'Sum_Trx_NoMonetarias_{}.parquet'.format(periodo)\n",
        "    df_tx = pd.read_parquet(file, columns=uc)\n",
        "\n",
        "    # Agrupo los registros por canales digitales y no digitales\n",
        "    df_tx = df_tx.groupby([\n",
        "        'ID_USER',\n",
        "        'CANAL_RATIO']) \\\n",
        "        .aggregate('sum') \\\n",
        "        .sort_values(by='ID_USER') \\\n",
        "        .reset_index()\n",
        "        \n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']=='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_NOMON_DIG'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal NO digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']!='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_NOMON_OTR'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    # Convertir las columnas de cantidades a enteros previo sacar los valores nulos\n",
        "    for i in ['CANT_OP_MON_DIG', 'CANT_OP_MON_OTR', 'CANT_OP_NOMON_DIG', 'CANT_OP_NOMON_OTR']:\n",
        "        df_estudio[i] = df_estudio[i].fillna(0)\n",
        "        df_estudio[i] = df_estudio[i].astype(int)\n",
        "        \n",
        "    # Eliminar los nulos de los montos\n",
        "    for i in ['MONT_OP_MON_DIG', 'MONT_OP_MON_OTR']:\n",
        "        df_estudio[i] = df_estudio[i].fillna(0)\n",
        "\n",
        "    return df_estudio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Proceso de incorporación de información de Reclamos\n",
        "\n",
        "El objeto de leer el archivo de reclamos es incorporar a la tabla de crosseling una nueva columnas con información de:\n",
        "\n",
        "- Cantidad de tickets registrados para la plataforma BANCON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tratar_reclamos(periodo: str, df_cons: pd.DataFrame):\n",
        "\n",
        "    file = DIR + 'Gestar_{}.parquet'.format(periodo)\n",
        "\n",
        "    df_gt = pd.read_parquet(file, columns=['ID_USER', 'TYPE MOTIVO GESTION BANCON'])\n",
        "\n",
        "    # Me quedo solo con lo que son Reclamos de BANCON y los cuento por usuario\n",
        "    df_gt = df_gt[df_gt['TYPE MOTIVO GESTION BANCON'].notnull()]\n",
        "    df_gt = df_gt.groupby(by=['ID_USER']).size().to_frame().reset_index()\n",
        "    df_gt.columns = ['ID_USER', 'CANT_REC_PD']\n",
        "\n",
        "    df_estudio = pd.merge(df_cons, df_gt, how='left', on='ID_USER', indicator=False)\n",
        "\n",
        "    # Convertir las columnas de cantidades a enteros previo sacar los valores nulos\n",
        "    df_estudio['CANT_REC_PD'] = df_estudio['CANT_REC_PD'].fillna(0)\n",
        "    df_estudio['CANT_REC_PD'] = df_estudio['CANT_REC_PD'].astype(int)\n",
        "\n",
        "    return df_estudio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Proceso Principal de incorporación de información al dataframe de Crosseling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\e21719832\\Documents\\Python\\trayecto3\\Data\\Export\\Crosseling_ampliado_202202.parquet\n",
            "c:\\Users\\e21719832\\Documents\\Python\\trayecto3\\Data\\Export\\Crosseling_ampliado_202203.parquet\n",
            "c:\\Users\\e21719832\\Documents\\Python\\trayecto3\\Data\\Export\\Crosseling_ampliado_202204.parquet\n"
          ]
        }
      ],
      "source": [
        "for periodo in PERIODOS:\n",
        "    \n",
        "    df_parcial = tratar_crosseling(periodo, df_usuarios)\n",
        "    df_parcial = tratar_movimientos(periodo, df_parcial)\n",
        "    df_parcial = tratar_reclamos(periodo, df_parcial)\n",
        "    \n",
        "    #### Grabar ####\n",
        "    file = DIR + 'Crosseling_ampliado_{}.parquet'.format(periodo)\n",
        "    df_parcial.to_parquet(file)\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "do4t0MwnAPYf",
        "N-b0ssnalrk6",
        "1GEQg1Rnou84"
      ],
      "name": "Abandono_Retención_Usuarios_BANCON.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "9a5f32d0676542e4e2bf7db8487c84e3169d994048782af8503f70e03a7f1e48"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
