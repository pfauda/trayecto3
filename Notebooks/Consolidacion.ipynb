{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do4t0MwnAPYf"
      },
      "source": [
        "<img align=\"right\" width=\"250\" height=\"150\" src=\"https://lh3.googleusercontent.com/p/AF1QipPWZQfa087JiVjutpUTVEGRnh6W214Wjm439gKQ=w1080-h608-p-no-v0\">\n",
        "\n",
        "## **Proyecto:** Retención de usuarios de la Plataforma Digital\n",
        "\n",
        "#### El objetivo de este notebook es incorporar como datos agregados al archivo de Crosseling, los datos de Usuarios, Movimientos, Reclamos y Turnos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-b0ssnalrk6"
      },
      "source": [
        "## Importación de librerias y datos globales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "B0Yb19t0Lpvi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "try:\n",
        "    # Monto la unidad de drive porque los archivos son muy grandes\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DIR = '/content/drive/MyDrive/Trayecto3-DataDriven/Data/'\n",
        "except:\n",
        "    # Sino lo consigo asumo que estoy trabajando local\n",
        "    DIR = os.path.abspath(r'..\\Data\\Export') + '\\\\'\n",
        "\n",
        "PERIODOS = ['202202', '202203', '202204']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lectura de archivo de usuarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JOTTWO09dQeW",
        "outputId": "a87ae4c5-f04c-42b4-a0c6-542e09dc105f"
      },
      "outputs": [],
      "source": [
        "file = DIR + 'Usuarios.csv'\n",
        "df_usuarios = pd.read_csv(file, encoding='latin-1', parse_dates=[\"FechaCreacion\", \"LAST_LOGIN\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filtro los registros que se crearon hace menos de tres meses ya que todos ellos no se pueden evaluar\n",
        "df_usuarios = df_usuarios[df_usuarios['FechaCreacion'] < dt.datetime(2022, 2, 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "fecha_corte =  dt.datetime(2022, 4, 30)\n",
        "df_usuarios[df_usuarios['LAST_LOGIN'] > fecha_corte] = fecha_corte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculo la cantidad de dias desde su último acceso a la plataforma \n",
        "df_usuarios['DIAS_SIN_USAR_PD'] = (fecha_corte - df_usuarios['LAST_LOGIN']).astype('timedelta64[D]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Calculo Antiguedad en dias la plataforma\n",
        "df_usuarios['ANTIGUEDAD_PD'] = (df_usuarios['LAST_LOGIN'] - df_usuarios['FechaCreacion']).astype('timedelta64[D]')\n",
        "# Filtro los registros sin antiguedad en la plataforma\n",
        "df_usuarios = df_usuarios.loc[df_usuarios['ANTIGUEDAD_PD'] > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Asumo que abandonó la PD si lleva mas de 90 dias sin hacer login\n",
        "df_usuarios[\"ABANDONO_PD\"] = ['Sí' if ( _ > 90 ) else 'No' for _ in df_usuarios[\"DIAS_SIN_USAR_PD\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_USER</th>\n",
              "      <th>FechaCreacion</th>\n",
              "      <th>LAST_LOGIN</th>\n",
              "      <th>SegFactor</th>\n",
              "      <th>DIAS_SIN_USAR_PD</th>\n",
              "      <th>ANTIGUEDAD_PD</th>\n",
              "      <th>ABANDONO_PD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43760</th>\n",
              "      <td>4ba14c4111824727926b819d7d619a7f</td>\n",
              "      <td>2020-06-21</td>\n",
              "      <td>2020-08-27</td>\n",
              "      <td>SMS</td>\n",
              "      <td>611.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140231</th>\n",
              "      <td>bfa9e34f5983494bb590267f43cad68d</td>\n",
              "      <td>2020-11-04</td>\n",
              "      <td>2021-10-20</td>\n",
              "      <td>SMS</td>\n",
              "      <td>192.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164833</th>\n",
              "      <td>6610a2952dae48a3b80ca534d51129a8</td>\n",
              "      <td>2021-11-30</td>\n",
              "      <td>2022-01-18</td>\n",
              "      <td>No tiene segundo factor</td>\n",
              "      <td>102.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64079</th>\n",
              "      <td>4a84bcfc862c4dbdadad38319930e650</td>\n",
              "      <td>2020-06-18</td>\n",
              "      <td>2020-10-30</td>\n",
              "      <td>SMS</td>\n",
              "      <td>547.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78513</th>\n",
              "      <td>7470ceb505c64e4db38008d8539652fe</td>\n",
              "      <td>2020-01-21</td>\n",
              "      <td>2021-01-12</td>\n",
              "      <td>SMS</td>\n",
              "      <td>473.0</td>\n",
              "      <td>357.0</td>\n",
              "      <td>Sí</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 ID_USER FechaCreacion LAST_LOGIN  \\\n",
              "43760   4ba14c4111824727926b819d7d619a7f    2020-06-21 2020-08-27   \n",
              "140231  bfa9e34f5983494bb590267f43cad68d    2020-11-04 2021-10-20   \n",
              "164833  6610a2952dae48a3b80ca534d51129a8    2021-11-30 2022-01-18   \n",
              "64079   4a84bcfc862c4dbdadad38319930e650    2020-06-18 2020-10-30   \n",
              "78513   7470ceb505c64e4db38008d8539652fe    2020-01-21 2021-01-12   \n",
              "\n",
              "                      SegFactor  DIAS_SIN_USAR_PD  ANTIGUEDAD_PD ABANDONO_PD  \n",
              "43760                       SMS             611.0           67.0          Sí  \n",
              "140231                      SMS             192.0          350.0          Sí  \n",
              "164833  No tiene segundo factor             102.0           49.0          Sí  \n",
              "64079                       SMS             547.0          134.0          Sí  \n",
              "78513                       SMS             473.0          357.0          Sí  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_usuarios.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lectura de archivo de Crosseling\n",
        "\n",
        "Se lee el archivo de crosseling, se filtra para individuos y se cruza con el archivo de usuarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRjSCKgXSiP5",
        "outputId": "b4d65924-b822-4606-a84a-ad9db5a00d7d"
      },
      "outputs": [],
      "source": [
        "def tratar_crosseling(periodo: str, df_usr: pd.DataFrame):\n",
        "\n",
        "  tcols = {\n",
        "    'PERIODO': str,\n",
        "    'ID_USER': str,\n",
        "    'RELACION': str,\n",
        "    'TIPOIMPN': str,\n",
        "    'NATUJURI': str,\n",
        "    'SUCURSAL': str,\n",
        "    'BCRASECT': str,\n",
        "    'BCRASEGO': str,\n",
        "    'GRUPO_CLIENTE': str,\n",
        "    'GRUPOGENERAL': str,\n",
        "    'SUBGRUPO': str,\n",
        "    'SEGMENTO_SUELDOS': str,\n",
        "    'SEGMENTO_BANCAS': str,\n",
        "    'SALDO_COMPUTO_SIST_2': float,\n",
        "    'SALDO_COMPUTO_SIST_CC_MB': float,\n",
        "    'SALDO_COMPUTO_SIST_CA_P': float,\n",
        "    'SALDO_COMPUTO_SIST_CC_P': float,\n",
        "    'SALDO_COMPUTO_SIST_FCI': float,\n",
        "    'FUM': str\n",
        "  }\n",
        "\n",
        "  file = DIR + 'Crosseling_{}.csv'.format(periodo)\n",
        "  df_crosseling = pd.read_csv(file, dtype=tcols, parse_dates=['FUM'], index_col=False)\n",
        "\n",
        "  # Solo me quedo con los 'Individuo sin actividad comercial'\n",
        "  df_crosseling = df_crosseling.loc[df_crosseling['GRUPOGENERAL'] == 'Individuo sin actividad comercial']\n",
        "  df_crosseling.drop('GRUPOGENERAL', axis=1, inplace=True)\n",
        "\n",
        "  # Cruzar con el archivo de usuarios y retornar\n",
        "  return pd.merge(df_usuarios, df_crosseling, how='inner', on = 'ID_USER')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Proceso de incorporación de información de Movimientos\n",
        "\n",
        "El objeto de leer el archivo de movimientos es incorporar a la tabla de crosseling nuevas columnas con información de:\n",
        "\n",
        "- Cantidad de movimientos monetarios y monto total realizados por medio de la plataforma digital\n",
        "- Cantidad de movimientos monetarios y monto total realizados por FUERA de la plataforma digital\n",
        "- Cantidad de movimientos NO monetarios y realizados por medio de la plataforma digital\n",
        "- Cantidad de movimientos NO monetarios y realizados por FUERA de la plataforma digital\n",
        "\n",
        "Total **6** nuevas variables\n",
        "\n",
        "La idea es tener es que el algoritmo de predicción elegido tenga información adicional para poder inferir si el cliente abandona o no la plataforma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tratar_movimientos(periodo: str, df_cons: pd.DataFrame):\n",
        "\n",
        "    uc = [\n",
        "        'ID_USER',\n",
        "        'CANAL_RATIO',\n",
        "        'CANT_OPERACIONES',\n",
        "        'MONTO_TOTAL'\n",
        "    ]\n",
        "\n",
        "    tc = {\n",
        "        'ID_USER': str,\n",
        "        'CANAL_RATIO': str,\n",
        "        'CANT_OPERACIONES': int,\n",
        "        'MONTO_TOTAL': float,\n",
        "    }\n",
        "\n",
        "    df_estudio = df_cons\n",
        "    \n",
        "    #### Transacciones Monetarias ####\n",
        "\n",
        "    file = DIR + r'Sum_Trx_Monetarias_{}.csv'.format(periodo)\n",
        "    df_tx = pd.read_csv(file, index_col=False, dtype=tc, usecols=uc)\n",
        "\n",
        "    # Agrupo y sumarizo los registros por canales digitales y no digitales\n",
        "    df_tx = df_tx.groupby([\n",
        "        'ID_USER',\n",
        "        'CANAL_RATIO']) \\\n",
        "        .aggregate('sum') \\\n",
        "        .sort_values(by='ID_USER') \\\n",
        "        .reset_index()\n",
        "\n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']=='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES', 'MONTO_TOTAL']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_MON_DIG', 'MONTO_TOTAL': 'MONT_OP_MON_DIG'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal NO digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']!='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES', 'MONTO_TOTAL']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_MON_OTR', 'MONTO_TOTAL': 'MONT_OP_MON_OTR'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    #### Transacciones No Monetarias ####\n",
        "    file = DIR + r'Sum_Trx_NoMonetarias_{}.csv'.format(periodo)\n",
        "    df_tx = pd.read_csv(file, index_col=False, dtype=tc, usecols=uc)\n",
        "\n",
        "    # Agrupo los registros por canales digitales y no digitales\n",
        "    df_tx = df_tx.groupby([\n",
        "        'ID_USER',\n",
        "        'CANAL_RATIO']) \\\n",
        "        .aggregate('sum') \\\n",
        "        .sort_values(by='ID_USER') \\\n",
        "        .reset_index()\n",
        "        \n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']=='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_NOMON_DIG'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    # Pongo en columnas la cantidad y monto de las transacciones por canal NO digital\n",
        "    df_tx_join = df_tx \\\n",
        "        .loc[(df_tx['CANAL_RATIO']!='DIGITAL'), ['ID_USER', 'CANT_OPERACIONES']] \\\n",
        "        .rename(columns = {'CANT_OPERACIONES': 'CANT_OP_NOMON_OTR'})\n",
        "    df_estudio = pd.merge(df_estudio, df_tx_join, how='left', on = 'ID_USER', indicator=False)\n",
        "\n",
        "    # Convertir las columnas de cantidades a enteros previo sacar los valores nulos\n",
        "    for i in ['CANT_OP_MON_DIG', 'CANT_OP_MON_OTR', 'CANT_OP_NOMON_DIG', 'CANT_OP_NOMON_OTR']:\n",
        "        df_estudio[i] = df_estudio[i].fillna(0)\n",
        "        df_estudio[i] = df_estudio[i].astype(int)\n",
        "        \n",
        "    # Eliminar los nulos de los montos\n",
        "    for i in ['MONT_OP_MON_DIG', 'MONT_OP_MON_OTR']:\n",
        "        df_estudio[i] = df_estudio[i].fillna(0)\n",
        "\n",
        "    return df_estudio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Proceso de incorporación de información de Reclamos\n",
        "\n",
        "El objeto de leer el archivo de reclamos es incorporar a la tabla de crosseling una nueva columnas con información de:\n",
        "\n",
        "- Cantidad de tickets registrados para la plataforma BANCON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tratar_reclamos(periodo: str, df_cons: pd.DataFrame):\n",
        "\n",
        "    file = DIR + 'Gestar_{}.csv'.format(periodo)\n",
        "\n",
        "    df_gt = pd.read_csv(file, usecols=['ID_USER', 'TYPE MOTIVO GESTION BANCON'], index_col=False)\n",
        "\n",
        "    # Me quedo solo con lo que son Reclamos de BANCON y los cuento por usuario\n",
        "    df_gt = df_gt[df_gt['TYPE MOTIVO GESTION BANCON'].notnull()]\n",
        "    df_gt = df_gt.groupby(by=['ID_USER']).size().to_frame().reset_index()\n",
        "    df_gt.columns = ['ID_USER', 'CANT_REC_PD']\n",
        "\n",
        "    df_estudio = pd.merge(df_cons, df_gt, how='left', on='ID_USER', indicator=False)\n",
        "\n",
        "    # Convertir las columnas de cantidades a enteros previo sacar los valores nulos\n",
        "    df_estudio['CANT_REC_PD'] = df_estudio['CANT_REC_PD'].fillna(0)\n",
        "    df_estudio['CANT_REC_PD'] = df_estudio['CANT_REC_PD'].astype(int)\n",
        "\n",
        "    return df_estudio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Proceso Principal de incorporación de información al dataframe de Crosseling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\e21719832\\Documents\\Python\\trayecto3\\Data\\Export\\Crosseling_ampliado_202202.csv\n",
            "c:\\Users\\e21719832\\Documents\\Python\\trayecto3\\Data\\Export\\Crosseling_ampliado_202203.csv\n",
            "c:\\Users\\e21719832\\Documents\\Python\\trayecto3\\Data\\Export\\Crosseling_ampliado_202204.csv\n"
          ]
        }
      ],
      "source": [
        "for periodo in PERIODOS:\n",
        "    \n",
        "    df_parcial = tratar_crosseling(periodo, df_usuarios)\n",
        "    df_parcial = tratar_movimientos(periodo, df_parcial)\n",
        "    df_parcial = tratar_reclamos(periodo, df_parcial)\n",
        "    \n",
        "    #### Grabar ####\n",
        "    file = DIR + 'Crosseling_ampliado_{}.csv'.format(periodo)\n",
        "    df_parcial.to_csv(file, index=False)\n",
        "    print(file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "do4t0MwnAPYf",
        "N-b0ssnalrk6",
        "1GEQg1Rnou84"
      ],
      "name": "Abandono_Retención_Usuarios_BANCON.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "9a5f32d0676542e4e2bf7db8487c84e3169d994048782af8503f70e03a7f1e48"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
